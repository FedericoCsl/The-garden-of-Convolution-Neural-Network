{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "807d7380-bd86-4376-9b6b-f7a18c1e25f9",
   "metadata": {},
   "source": [
    "# The garden of Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b974ea54-3513-498c-bef5-2ebc95d2f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libreries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37fbf57-6aa1-4aa3-837d-7cfe713fd641",
   "metadata": {},
   "source": [
    "### Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfc2dd-1d2f-4292-948b-06e90e3af50e",
   "metadata": {},
   "source": [
    "#### Training Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d0f43d8b-f18f-403d-ac12-9ae01e72ba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3680 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagenerator_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_set = datagenerator_train.flow_from_directory(\n",
    "                \"train_set\", target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f712853-6dbd-4a2d-9d77-6da5d9e8f910",
   "metadata": {},
   "source": [
    "#### Test Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8ff45d53-12a6-4ce2-80a1-5434562bd01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 637 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagenerator_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = datagenerator_test.flow_from_directory(\n",
    "               \"test_set\", target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d74a7-4c5b-450d-9840-18ca77e55782",
   "metadata": {},
   "source": [
    "### How to build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0ea58d75-037f-4cba-ac43-dfadf23e42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cca735-e13c-4e45-a737-e7d196ad9bd2",
   "metadata": {},
   "source": [
    "### How to build the Convolution Layer  --https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "59d0777a-373e-4817-966f-d0198d0d2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation=\"relu\",input_shape=[64,64,3])) #Convolution layer (CONV)\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))  # Pooling (POOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed262776-87ec-4c17-99ea-b9e5b7350683",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation=\"relu\",input_shape=[64,64,3])) #Convolution layer (CONV)\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))  # Pooling (POOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "868a5fa4-ab14-497d-b2b1-23ecf51d712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give at least 2 layers to make the model more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "772a7be7-bdf9-47cf-b193-c75b94c84ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation=\"relu\")) #Convolution layer (CONV)\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))  # Pooling (POOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4ec25fed-fb69-4cb3-aae3-a66958da0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=96,kernel_size=3,activation ='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c711ea0f-16d3-46a4-8736-1e5bb4577ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6b5947bf-d5b8-446f-b2c4-4e78fde1ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e8749872-7f26-4315-b202-b2ab0d4f1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation=\"relu\")) # for hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "32569392-7327-4d7d-94d2-c360f5fa77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=5,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bde39a-c88d-47ee-afcf-be4533aa8cf5",
   "metadata": {},
   "source": [
    "#### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df98815-8f19-4cdf-8b97-d78012f2c2f3",
   "metadata": {},
   "source": [
    "###### if you check on the website \"https://keras.io/api/optimizers/\" you will find different types of optimizers, after trying a few ones, the one with the best result is RMSprop, lets check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0ca215f3-3f4e-4972-af7b-c6b624515100",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e42533b9-f5e3-487b-88ea-87e7eafa3f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "115/115 [==============================] - 79s 662ms/step - loss: 1.3723 - accuracy: 0.3924 - val_loss: 1.2958 - val_accuracy: 0.4553\n",
      "Epoch 2/30\n",
      "115/115 [==============================] - 88s 768ms/step - loss: 1.1588 - accuracy: 0.5179 - val_loss: 0.9955 - val_accuracy: 0.5918\n",
      "Epoch 3/30\n",
      "115/115 [==============================] - 84s 726ms/step - loss: 1.0451 - accuracy: 0.5766 - val_loss: 1.0593 - val_accuracy: 0.5903\n",
      "Epoch 4/30\n",
      "115/115 [==============================] - 75s 647ms/step - loss: 0.9732 - accuracy: 0.6207 - val_loss: 0.8950 - val_accuracy: 0.6703\n",
      "Epoch 5/30\n",
      "115/115 [==============================] - 70s 606ms/step - loss: 0.9125 - accuracy: 0.6562 - val_loss: 0.8810 - val_accuracy: 0.6248\n",
      "Epoch 6/30\n",
      "115/115 [==============================] - 70s 604ms/step - loss: 0.8804 - accuracy: 0.6552 - val_loss: 0.8605 - val_accuracy: 0.6641\n",
      "Epoch 7/30\n",
      "115/115 [==============================] - 71s 621ms/step - loss: 0.8590 - accuracy: 0.6791 - val_loss: 0.9267 - val_accuracy: 0.6499\n",
      "Epoch 8/30\n",
      "115/115 [==============================] - 70s 602ms/step - loss: 0.8235 - accuracy: 0.6823 - val_loss: 0.7665 - val_accuracy: 0.7143\n",
      "Epoch 9/30\n",
      "115/115 [==============================] - 72s 626ms/step - loss: 0.7764 - accuracy: 0.7022 - val_loss: 1.1441 - val_accuracy: 0.6170\n",
      "Epoch 10/30\n",
      "115/115 [==============================] - 71s 616ms/step - loss: 0.7735 - accuracy: 0.7155 - val_loss: 0.8035 - val_accuracy: 0.7002\n",
      "Epoch 11/30\n",
      "115/115 [==============================] - 72s 619ms/step - loss: 0.7464 - accuracy: 0.7193 - val_loss: 0.8745 - val_accuracy: 0.6797\n",
      "Epoch 12/30\n",
      "115/115 [==============================] - 73s 634ms/step - loss: 0.7176 - accuracy: 0.7315 - val_loss: 0.7640 - val_accuracy: 0.7096\n",
      "Epoch 13/30\n",
      "115/115 [==============================] - 70s 604ms/step - loss: 0.7213 - accuracy: 0.7375 - val_loss: 0.8413 - val_accuracy: 0.6531\n",
      "Epoch 14/30\n",
      "115/115 [==============================] - 79s 683ms/step - loss: 0.7080 - accuracy: 0.7332 - val_loss: 0.8022 - val_accuracy: 0.7049\n",
      "Epoch 15/30\n",
      "115/115 [==============================] - 77s 664ms/step - loss: 0.6675 - accuracy: 0.7451 - val_loss: 0.7771 - val_accuracy: 0.6876\n",
      "Epoch 16/30\n",
      "115/115 [==============================] - 73s 635ms/step - loss: 0.6482 - accuracy: 0.7576 - val_loss: 0.7478 - val_accuracy: 0.7111\n",
      "Epoch 17/30\n",
      "115/115 [==============================] - 71s 615ms/step - loss: 0.6361 - accuracy: 0.7543 - val_loss: 0.9071 - val_accuracy: 0.6703\n",
      "Epoch 18/30\n",
      "115/115 [==============================] - 68s 592ms/step - loss: 0.6253 - accuracy: 0.7709 - val_loss: 0.7625 - val_accuracy: 0.7049\n",
      "Epoch 19/30\n",
      "115/115 [==============================] - 80s 693ms/step - loss: 0.6224 - accuracy: 0.7712 - val_loss: 0.6966 - val_accuracy: 0.7378\n",
      "Epoch 20/30\n",
      "115/115 [==============================] - 129s 1s/step - loss: 0.5993 - accuracy: 0.7796 - val_loss: 0.7604 - val_accuracy: 0.7300\n",
      "Epoch 21/30\n",
      "115/115 [==============================] - 117s 1s/step - loss: 0.5790 - accuracy: 0.7867 - val_loss: 0.8293 - val_accuracy: 0.7237\n",
      "Epoch 22/30\n",
      "115/115 [==============================] - 93s 800ms/step - loss: 0.5866 - accuracy: 0.7818 - val_loss: 0.7443 - val_accuracy: 0.7049\n",
      "Epoch 23/30\n",
      "115/115 [==============================] - 74s 639ms/step - loss: 0.5540 - accuracy: 0.7992 - val_loss: 0.9584 - val_accuracy: 0.6468\n",
      "Epoch 24/30\n",
      "115/115 [==============================] - 129s 1s/step - loss: 0.5493 - accuracy: 0.7927 - val_loss: 0.9106 - val_accuracy: 0.6970\n",
      "Epoch 25/30\n",
      "115/115 [==============================] - 137s 1s/step - loss: 0.5390 - accuracy: 0.7973 - val_loss: 0.8753 - val_accuracy: 0.7127\n",
      "Epoch 26/30\n",
      "115/115 [==============================] - 95s 816ms/step - loss: 0.5364 - accuracy: 0.7986 - val_loss: 0.8501 - val_accuracy: 0.7221\n",
      "Epoch 27/30\n",
      "115/115 [==============================] - 70s 605ms/step - loss: 0.5329 - accuracy: 0.8082 - val_loss: 0.7473 - val_accuracy: 0.7331\n",
      "Epoch 28/30\n",
      "115/115 [==============================] - 75s 653ms/step - loss: 0.5130 - accuracy: 0.8087 - val_loss: 0.8711 - val_accuracy: 0.7159\n",
      "Epoch 29/30\n",
      "115/115 [==============================] - 78s 676ms/step - loss: 0.5257 - accuracy: 0.8109 - val_loss: 0.7397 - val_accuracy: 0.7363\n",
      "Epoch 30/30\n",
      "115/115 [==============================] - 69s 596ms/step - loss: 0.5056 - accuracy: 0.8109 - val_loss: 0.9651 - val_accuracy: 0.7080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28955250040>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train_set,validation_data=test_set,epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03294e-9e55-4fa9-9bff-d81ff3f440bd",
   "metadata": {},
   "source": [
    "#### Now its time to preprocess the pics I took from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b1eb3c66-1a63-4ae4-8316-78a2ead56813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028955DF20D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 216ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "image = tf.keras.preprocessing.image.load_img(\"prediction/daisy_pic.jpg\",target_size=(64,64))\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = cnn.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "77f9ca23-f3b7-45f4-9912-12a599bbfd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "803e196e-6ca1-429b-9ece-910a55dd808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36961072-67e1-414e-b795-5034ca266568",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7cede967-9045-44dd-b9c5-6625f44925e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn.h5\"\n",
    "cnn.save(model_name, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb968bf-cf18-49e0-9a84-08403825e44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb979822-f741-4026-890c-b8b5a18b8a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
